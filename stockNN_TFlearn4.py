
'''
examples that use tflearn high layer API to implement DNN classifier with StockNN network structure pre-verified with irisdata

previous version is stockNN_loadIris_TFLearn.py

updated on 2017-9-22 process data format for data 201101-201612

'''


from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tflearn
import time

import tensorflow as tf

# Data sets
TRAINDATASTART = 1      # the row# of the beginning of training data
TRAINDATASTOP = 1132174  # the row# of the end of the training data record  2013-2015csv file
TESTDATASTART=1     # the row# of the starting in test csv file 2016-2017
TESTDATASTOP=1048576  # the last row of the whole file, this row# is excluded in test data

TrainDataStart = 1
TrainDataStop = TRAINDATASTOP  #for debugging purpose ,you can adjust this to get a small part for time saving now
TestDataStart = 1 #350603
TestDataStop = TESTDATASTOP     # for debugging purpose ,you can adjust this to get a small part for time saving now


hyperParamSetFile = "HyperParamSearchPlan.csv"          #file is generated by genParamCsv.py and reviewed manually

import datetime
from tensorflow.python.platform import gfile
# from sklearn.externals import joblib

#the following packages  are part of the project
from utility import log,plotFeatures
from fetchData import FetchData
from dnnModel import DnnModel
from preprocess import DataPreprocess,dataPreprocessDumpfile
from hyperParam import HyperParam,supportedSkip,selectedAvgline




def main():

  # show the overall profit or loss rate when strictly follow the rule of buying and selling stock for each selectedAvgLine
  # load_csv_calc_profit(trainfilename,start_rowid=TrainDataStart,end_rowid=TrainDataStop,
  #                      fromDate='2010/12/31',
  #                      toDate='2016/12/29',
  #                      target_column=-1,
  #                      selectedAvgline=selectedAvgline)
  #
  # load_csv_calc_profit(testfilename, start_rowid=TestDataStart, end_rowid=TestDataStop,
  #                      fromDate='2016/12/30',
  #                      toDate='2017/09/19',
  #                      target_column=-1,
  #                      selectedAvgline=selectedAvgline)
  # return

  runStartTime=time.time()  # start time in ms.
  st=time.ctime()  #start time in date/time format

  # instantiate a HyperParam class to read  hyperparameter search plan into a list
  # do sanity check to make sure all input parameters are valid before going further
  try:
        hpIns = HyperParam(hyperParamSetFile)
        hpIns.sanityCheck()
  except ValueError as e:
        log("\nValueError Exception:")
        log(e.message)
        return
  except KeyError as e:
        log("KeyError Exception happened")
        log(e.message)
        return

  else:
        log("\n sanity check on search plan file(%s) PASSED " %hyperParamSetFile)

  modelIsTrained=False
  for  seqid in range(0,hpIns.rows.__len__()):
        try:
          preProcessChanged,hpDict = hpIns.readRow(rowId=seqid)
        except ValueError as e:
            log("WARNING: exception captured")
            log(e.message)
            log("\nSkip seqid=%d  and continue to next iteration, please double check your settings in %s" %(seqid,hpIns.filename))
            continue

        if hpDict['Skip'] == supportedSkip[2] or hpDict['Skip']==supportedSkip[3]:   # this row is comment out, not run
            continue

        if not modelIsTrained:  # need to train the model
            # Load datasets.

            log('\n%d ---> loading training data from file %s from:%s,to:%s in progress ... time:%s'
                % (seqid,hpDict["Train"], hpDict["TFromDate"],hpDict["TToDate"],st))
            # Load datasets. discard column 0,1,3,4 in the original csvfile ,which represent  id ,tradedate,mc_date,datadate
            fd=FetchData(hpDict["Train"],hpDict["TFromDate"],hpDict["TToDate"],TrainDataStart,TrainDataStop)
            try:
                training_set=fd.loadData()
            except ValueError as e:
                print('=' * 30 + "ValueError Exception happened:" + '=' * 30)
                print(e)
                print('=' * 30 + "end of print ValueError exception" + '=' * 30)
                log("ValueError occurred in loading training data, skip this iteration")
                continue

            # plot original data to review
            # plotFeatures(training_set.data,training_set.featurenames,[1],"Orig11Jan-16Dectrain",savePlotToDisk=True,scatterAdjust=False)

            log('\nloading test data from file %s from:%s,to:%s in progress ... time:%s'
                % (hpDict["Test"], hpDict["TestFromD"],hpDict["TestToD"],time.ctime()))
            fd=FetchData(hpDict["Test"],hpDict["TestFromD"],hpDict["TestToD"],TestDataStart,TestDataStop)
            try:
                test_set=fd.loadData()
            except ValueError as e:
                print('=' * 30 + "ValueError Exception happened:" + '=' * 30)
                print(e)
                print('=' * 30 + "end of print ValueError exception" + '=' * 30)
                log("ValueError occurred in loading test data, skip this iteration")
                continue
            # plot original test data to review
            # plotFeatures(test_set.data,test_set.featurenames,[1],"Orig17Jan-17Septest",savePlotToDisk=True,scatterAdjust=False)

            y = training_set.target

            y_test = test_set.target
            #think about  reload training set and test_set , next optimal target is do not spend time reloading if
            # this round has the same training, test filename as well as from/todate # ????

            # since we load training data and test data, it's safe to start everything from scratch, forget the last iteration
            #if preProcessChanged:  # this row's preprocessor is different from last one,apply preprocessing
            #log('\n Seqno %d : preProcess is required to be redone,since we need to apply a preprocessor different from last run' %seqid)

            dp = DataPreprocess(hpDict['Preprocessor'])
            dp.fit(training_set)
            X = dp.transform(training_set)
            #for debugging purpose, plot any  feature ids for manually checking their values after transform
            #plotFeatures(X, training_set.featurenames, [0,1,2,43,112],hpDict['Preprocessor']+str(seqid)+'train',savePlotToDisk=True,scatterAdjust=False)
            X_test = dp.transform(test_set)   #use the same scaler to transform test_set.data
            #plotFeatures(X_test, test_set.featurenames, [0,1,2,43,112],hpDict['Preprocessor']+str(seqid)+'test',savePlotToDisk=True,scatterAdjust=False)
            #del dp  # release the instance of dp, give system chance to gc it
            # else:
            #     log("\nSeqno %d : Skip preprocess since this is the same preprocessor as the last time,X,X_test have been preprocessed last time" %seqid)


            # try pca
            # X_test = pca.transform(X_test)
            log('\nbuilding model in progress ... time:%s' % (time.ctime()))


            tf.reset_default_graph()
            runId = tflearn.utils.id_generator()
            mymodel = DnnModel(hpDict,runId)
            mymodel.train(X,y,X_test,y_test)
            mymodel.saveModel(hpDict,dp,dataPreprocessDumpfile)   # save the whole model including it data preprocess method and datascaler
            mymodel.evaluate(hpDict,X,y,X_test,y_test)
            modelIsTrained=True
            del mymodel  # delete instance of DNNModel since its task has come to an end. let system to gc it
            del test_set,X_test,y_test
            del training_set,X,y

        else:   #only predict and evaluate ,skip training process
          #initiate a empty model, load the weight from the the saved model to reevaluate,double check the model's load function
            log('\nloading test data from file %s from:%s,to:%s in progress ... time:%s'
              % (hpDict["Test"], hpDict["TestFromD"], hpDict["TestToD"], time.ctime()))
            fd = FetchData(hpDict["Test"], hpDict["TestFromD"], hpDict["TestToD"], TestDataStart, TestDataStop)
            try:
                test_set = fd.loadData()
            except ValueError as e:
                print('=' * 30 + "ValueError Exception happened:" + '=' * 30)
                print(e)
                print('=' * 30 + "end of print ValueError exception" + '=' * 30)
                log("ValueError occurred in loading test data, skip this iteration")
                continue
          # plot original test data to review
          # plotFeatures(test_set.data,test_set.featurenames,[1],"Orig17Jan-17Septest",savePlotToDisk=True,scatterAdjust=False)




            tf.reset_default_graph()
            y_test = test_set.target
            loadmymodel = DnnModel(hpDict,runId+'load'+hpDict['Seqno'])  # use this runId + seqno combination as <runid> to distinguish multiple load models from original model, don't retrain the model
            try:
                loadmymodel.loadModel(hpDict,runId,dataPreprocessDumpfile)         # load its preprocess and datascaler
                X_test= loadmymodel.dpp.transform(test_set)  # use the same scaler to transform test_set.data
            except IOError as ve:  #can't find the trained model from disk
                log(ve.message)
                log("\nWARNING:  Skip this evaluation process ... ")
                continue
            except Exception:    # any other exceptions, just skip this evaluation, not a big deal
                log("\nWARNING:  Exception occurred, skip this evaluation... ")
                continue
            else:
                loadmymodel.evaluateTestSet(hpDict,X_test,y_test) # output the ROC to disk with <runid>load folder name
                log('\nload trained model & reevaluate completed! ')
            del loadmymodel  # delete instance of DNNModel since its task has come to an end. let system to gc it
            del test_set, X_test, y_test


  endTime = time.time()  # end time in ms.
  elapseTime = (endTime - runStartTime)
  hour = int(elapseTime / 3600)
  minute = int((elapseTime % 3600) / 60)
  second = int((elapseTime % 3600) % 60)
  duration = "%dh%d'%d''" % (hour, minute, second)
  log("\nthe WHOLE ELAPSED time of loading data and training all the models is %s"% (duration))


      # keyp = raw_input("\nPlease input a row# to predict: (-1 to quit)")
      # while (keyp != '-1'):
      #     rowid=int(keyp)
      #     tmp=X_test[rowid,:]
      #     #tmp=tmp.reshape(tmp.shape[0],1)
      #     pred= model.predict(tmp)
      #     print ("predicted y label = %d, true y label is %d" %(np.argmax(pred, axis=1),y_test[rowid,:] ))
      #
      #     keyp = raw_input("\nPlease input a row# to predict: (-1 to quit)")
      # log("End of program")



if __name__ == "__main__":
    main()
